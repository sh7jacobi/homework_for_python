{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "from NTS_prev_umf import NTS\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Равномерное разбиение отрезка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r - разбиение, x - x_o из изначальной задачи\n",
    "def function_uniform(x, r = t.linspace(0,1,n)):\n",
    "    len_x = x.size()[0]\n",
    "    g = t.ones(len_x)\n",
    "    for i in range(len_x):\n",
    "        # first = ( r[i+1].sub(x[i]) ).div( x[i].sub(r[i]) ).abs().log()\n",
    "        first = t.log((r[i+1] - x[i]) / (x[i] - r[i])) \n",
    "        second = t.zeros(1)\n",
    "        for k in range(len_x-1):\n",
    "            if k!=i:\n",
    "                second = second + t.log((r[k+1] - x[i]) / (r[k] - x[i])) + (x[k] - x[i]) * (1 / (r[k+1] - x[i]) - 1 / (r[k] - x[i]))\n",
    "        g[i] = first + second\n",
    "    return g    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_function_uniform(x, r = t.linspace(0,1,n)):\n",
    "    len = x.size()[0]\n",
    "    dg = t.zeros([len, len])\n",
    "\n",
    "    for i in range(len):\n",
    "        for j in range(len):\n",
    "            if i == j:\n",
    "                dg[i][j] = - t.abs(1. / (r[i+1] - x[i])) - t.abs(1. / (x[i] - r[i]))\n",
    "                for k in range(len-1):\n",
    "                    if k!=i:\n",
    "                        dg[i][j] += -1. / (r[k+1] - x[i]) + 1. / (r[k] - x[i]) + (1. / (r[k] - x[i]) - 1./(r[k+1] - x[i])) + (x[k] - x[i]) * (1. / (r[k+1] - x[i]).square() - 1. / (r[k] - x[i]).square())\n",
    "            else:\n",
    "                dg[i][j] = 1. / (r[j+1] - x[i]) - 1. / (r[j] - x[i])\n",
    "    return dg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_N(function, optimizer, x, epoch):\n",
    "    \n",
    "    loss_line = []\n",
    "    \n",
    "    x_last = t.zeros_like(x)\n",
    "    \n",
    "    eps = 100\n",
    "    step = 0\n",
    "    while step < epoch:\n",
    "        \n",
    "        with t.no_grad():\n",
    "            f = (function(x) ** 2).sum()\n",
    "            loss_line.append(f)\n",
    "        \n",
    "        with t.no_grad():\n",
    "            x_last.copy_(x)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        optimizer.step()\n",
    "        \n",
    "        eps = ((x - x_last) ** 2).sum().sqrt()\n",
    "        step += 1\n",
    "    \n",
    "        #print(' ' * 60, end='\\r')\n",
    "        print('eps = {}  step = {}     '.format(eps, step), end='\\r')\n",
    "    \n",
    "    print(' ' * 60, end='\\r')\n",
    "    print('eps = {} step = {} f = {}'.format(eps.tolist(), step, f))\n",
    "    print(x.tolist())\n",
    "        \n",
    "    return loss_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yakub/Desktop/summer_project/env/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "r = t.linspace(0,1,n)\n",
    "x = r[:-1]+(r[1]-r[0])/4.0\n",
    "x = t.tensor(x,  dtype= t.float32, requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps = 0.0 step = 100 f = 4.784292697906494                  \n",
      "[0.055509019643068314, 0.1030096709728241, 0.1771797388792038, 0.24834008514881134, 0.31970059871673584, 0.3911381959915161, 0.4625542461872101, 0.5339847803115845, 0.6054207682609558, 0.6768724918365479, 0.7483736872673035, 0.8198472857475281, 0.8916033506393433, 0.9649708867073059]\n",
      "time = 18.942607879638672\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "optimizer = NTS([x], function_uniform, grad_function_uniform, epoch=10, adaptive_lr=True,adaptive_L=True, limit_L=1e-2, limit_recurse=4, lr=1e-2)\n",
    "loss = train_N(function_uniform,optimizer,x,100) \n",
    "print('time = {}'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fcfe86a4550>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_s(function, optimizer, x, epoch):\n",
    "    \n",
    "    loss_line = []\n",
    "    \n",
    "    x_last = t.zeros_like(x)\n",
    "    \n",
    "    eps = 100\n",
    "    step = 0\n",
    "    while step < epoch:\n",
    "        f = (function(x) ** 2).sum()\n",
    "        \n",
    "        with t.no_grad():\n",
    "            loss_line.append(f)\n",
    "        \n",
    "        with t.no_grad():\n",
    "            x_last.copy_(x)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        f.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        eps = ((x - x_last) ** 2).sum().sqrt()\n",
    "        step += 1\n",
    "    \n",
    "        #print(' ' * 60, end='\\r')\n",
    "        print('eps = {}  step = {}    '.format(eps, step), end='\\r')\n",
    "    \n",
    "    print(' ' * 60, end='\\r')\n",
    "    print('eps = {} step = {} f = {}'.format(eps.tolist(), step, f))\n",
    "    print(x.tolist())\n",
    "        \n",
    "    return loss_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = t.linspace(0,1,n)\n",
    "x = r[:-1]+(r[1]-r[0])/4.0\n",
    "x = t.tensor(x,  dtype= t.float32, requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam([x], lr=1e-3)\n",
    "loss = train_s(function_uniform, optimizer, x, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Неравномерное разбиение отрезка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_norm_split(n):\n",
    "    \n",
    "    n1 = n // 2\n",
    "    n2 = n - n1\n",
    "    \n",
    "    r1 = t.randn(n1).abs() / 3\n",
    "    r2 = 1 - t.randn(n2).abs() / 3\n",
    "    \n",
    "    return t.cat([r1, r2]).sort()[0]\n",
    "\n",
    "def generate_norm_x(r):\n",
    "    \n",
    "    x = t.zeros_like(r[:-1])\n",
    "    \n",
    "    for i, _ in enumerate(x):\n",
    "        x[i] = r[i] + (r[i + 1] - r[i]) / 4.\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r - разбиение, x - x_o из изначальной задачи\n",
    "def function_normal(x):\n",
    "    \n",
    "    global r\n",
    "    \n",
    "    len_x = x.size()[0]\n",
    "    g = t.ones(len_x)\n",
    "    for i in range(len_x):\n",
    "        # first = ( r[i+1].sub(x[i]) ).div( x[i].sub(r[i]) ).abs().log()\n",
    "        first = t.log((r[i+1] - x[i]) / (x[i] - r[i])) \n",
    "        second = t.zeros(1)\n",
    "        for k in range(len_x-1):\n",
    "            if k!=i:\n",
    "                second = second + t.log((r[k+1] - x[i]) / (r[k] - x[i])) + (x[k] - x[i]) * (1 / (r[k+1] - x[i]) - 1 / (r[k] - x[i]))\n",
    "        g[i] = first + second\n",
    "    return g    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = generate_norm_split(n)\n",
    "x0 = generate_norm_x(r)\n",
    "print(r)\n",
    "print(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = t.zeros_like(x0, requires_grad=True)\n",
    "with t.no_grad():\n",
    "    x.copy_(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam([x], lr=1e-4)\n",
    "loss_Adam = train_s(function_normal, optimizer, x, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_Adam[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_Adam[-100:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = t.zeros_like(x0, requires_grad=True)\n",
    "with t.no_grad():\n",
    "    x.copy_(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = NTS([x], function_normal, epoch=10, adaptive_lr=True,\n",
    "                adaptive_L=True, limit_L=1e-2, limit_recurse=4, lr=1e-2)\n",
    "loss_NTS = train_N(function_normal, optimizer ,x , 1000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x0)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(loss_NTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_NTS[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x > r[:-1]) & (x < r[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "junc_line = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "junc_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
